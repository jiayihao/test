{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0c0bb9-64ad-4982-92da-a0daa2cf972c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = \"5a2109a4be6c42349cf136cec9d84644\"\n",
    "openai.api_base = \"https://agi-openai.openai.azure.com\"\n",
    "openai.api_version = \"2023-03-15-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce0fd9-5d97-40c7-8e97-28a30d116583",
   "metadata": {},
   "source": [
    "## ç¤ºä¾‹ï¼šå•è½®/å¤šè½®å¯¹è¯è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993954f-737d-4396-a227-8d4908cb6f3d",
   "metadata": {},
   "source": [
    "### å•è½®å¯¹è¯è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc25c9f-9605-417a-aaa6-29218de1f17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"{Je t'aime}\"\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates English to French.\"},\n",
    "  {\"role\": \"user\", \"content\": '\"{I Love You}\"'}\n",
    "],\n",
    "    temperature=0.7,\n",
    "    deployment_id='gtp35')\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9057ae8a-1450-4401-a2bb-6440b3a0e320",
   "metadata": {},
   "source": [
    "### å¤šè½®å¯¹è¯è¾“å‡º+æµè¾“å‡º\n",
    "ä¸‹ä¸ºä¸€ä¸ªå®ç°å¤šè½®å¯¹è¯çš„ä¾‹å­ï¼Œè¾“å…¥\"end\"ç»“æŸå¯¹è¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f85d40bd-5d09-42c0-8d47-6cbcc9c8ffbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " å¸®æˆ‘ç”Ÿæˆä¸€æ®µæœ´ç´ è´å¶æ–¯çš„ä»£ç \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "å¥½çš„ï¼Œä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„Pythonå®ç°ï¼š\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "class NaiveBayes:\n",
      "    def fit(self, X, y):\n",
      "        self.X = X\n",
      "        self.y = y\n",
      "        self.classes = np.unique(y)\n",
      "        self.parameters = []\n",
      "        for i, c in enumerate(self.classes):\n",
      "            X_c = X[y == c]\n",
      "            self.parameters.append([])\n",
      "            for j in range(X.shape[1]):\n",
      "                mu, std = X_c[:, j].mean(), X_c[:, j].std()\n",
      "                self.parameters[i].append((mu, std))\n",
      "\n",
      "    def _calculate_likelihood(self, mean, std, x):\n",
      "        exponent = np.exp(-((x - mean) ** 2 / (2 * std ** 2)))\n",
      "        return np.log(exponent / (np.sqrt(2 * np.pi) * std))\n",
      "\n",
      "    def _calculate_prior(self, c):\n",
      "        return np.mean(self.y == c)\n",
      "\n",
      "    def predict(self, X):\n",
      "        y_pred = []\n",
      "        for x in X:\n",
      "            posteriors = []\n",
      "            for i, c in enumerate(self.classes):\n",
      "                prior = self._calculate_prior(c)\n",
      "                likelihood = np.sum(self._calculate_likelihood(*self.parameters[i][j], x[j]) for j in range(len(self.parameters[i])))\n",
      "                posterior = prior + likelihood\n",
      "                posteriors.append(posterior)\n",
      "            y_pred.append(self.classes[np.argmax(posteriors)])\n",
      "        return y_pred\n",
      "```\n",
      "\n",
      "è¯¥å®ç°åŸºäºé«˜æ–¯åˆ†å¸ƒå‡è®¾ï¼Œå¯ä»¥å¤„ç†è¿ç»­å‹æ•°æ®ã€‚è°ƒç”¨ `fit()` æ–¹æ³•æ¥æ‹Ÿåˆæ¨¡å‹ï¼Œç„¶åè°ƒç”¨ `predict()` æ–¹æ³•æ¥åšå‡ºé¢„æµ‹ã€‚"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " å†™ä¸€ä¸‹æœ´ç´ è´å¶æ–¯çš„æ•°å­¦å…¬å¸\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨æ˜¯ä¸€ç§åŸºäºè´å¶æ–¯å®šç†çš„æ¦‚ç‡åˆ†ç±»ç®—æ³•ï¼Œå®ƒå‡è®¾ä¸åŒç‰¹å¾ä¹‹é—´æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œè¿™ç§å‡è®¾è¢«ç§°ä¸ºâ€œæœ´ç´ â€ï¼ˆnaiveï¼‰ï¼Œå› æ­¤ç§°ä¸ºæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼ˆNaive Bayes Classifierï¼‰ã€‚ å…¶åˆ†ç±»åŸç†å¦‚ä¸‹ï¼š\n",
      "\n",
      "å‡è®¾ä¸€ä¸ªæ ·æœ¬ $x$ åŒ…å« $n$ ä¸ªç‰¹å¾ $x_1, x_2, ..., x_n$ï¼Œé‚£ä¹ˆæ ¹æ®è´å¶æ–¯å®šç†ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š\n",
      "\n",
      "$$P(y|x_1, x_2, ..., x_n) = \\frac{P(x_1, x_2, ..., x_n|y)P(y)}{P(x_1, x_2, ..., x_n)}$$\n",
      "\n",
      "å…¶ä¸­ $y$ æ˜¯æ ·æœ¬çš„ç±»åˆ«ã€‚\n",
      "\n",
      "æ ¹æ®æœ´ç´ è´å¶æ–¯çš„å‡è®¾ï¼Œä¸åŒç‰¹å¾ä¹‹é—´æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œæ‰€ä»¥å¯ä»¥å°† $P(x_1, x_2, ..., x_n|y)$ åˆ†è§£ä¸ºå„ä¸ªç‰¹å¾çš„æ¡ä»¶æ¦‚ç‡çš„ä¹˜ç§¯ï¼š\n",
      "\n",
      "$$P(x_1, x_2, ..., x_n|y) = P(x_1|y)P(x_2|y)...P(x_n|y)$$\n",
      "\n",
      "å°†ä¸Šè¿°å…¬å¼ä»£å…¥è´å¶æ–¯å…¬å¼ä¸­ï¼Œå¾—åˆ°ï¼š\n",
      "\n",
      "$$P(y|x_1, x_2, ..., x_n) = \\frac{P(y) \\prod_{i=1}^n P(x_i|y)}{P(x_1, x_2, ..., x_n)}$$\n",
      "\n",
      "ç”±äº $P(x_1, x_2, ..., x_n)$ å¯¹äºæ‰€æœ‰çš„ $y$ éƒ½æ˜¯ç›¸åŒçš„ï¼Œå› æ­¤å¯ä»¥ç®€åŒ–ä¸ºï¼š\n",
      "\n",
      "$$P(y|x_1, x_2, ..., x_n) \\propto P(y) \\prod_{i=1}^n P(x_i|y)$$\n",
      "\n",
      "å…¶ä¸­ $\\propto$ è¡¨ç¤ºâ€œä¸ä¹‹æˆæ¯”ä¾‹â€ã€‚\n",
      "\n",
      "æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„è®­ç»ƒè¿‡ç¨‹å°±æ˜¯ä¼°è®¡ $P(y)$ å’Œ $P(x_i|y)$ çš„è¿‡ç¨‹ã€‚å¯¹äºç¦»æ•£å‹ç‰¹å¾ï¼Œ$P(x_i|y)$ å¯ä»¥é€šè¿‡ç®€å•çš„ç»Ÿè®¡è®¡ç®—å¾—åˆ°ï¼Œä¾‹å¦‚ï¼š\n",
      "\n",
      "$$P(x_i = a|y = c) = \\frac{\\text{åœ¨ç±»åˆ«ä¸º c çš„æ ·æœ¬ä¸­ï¼Œç‰¹å¾} x_i \\text{å–å€¼ä¸º} a \\text{çš„æ ·æœ¬æ•°}}{\\text{ç±»åˆ«ä¸º c çš„æ ·æœ¬æ€»æ•°}}$$\n",
      "\n",
      "å¯¹äºè¿ç»­å‹ç‰¹å¾ï¼Œé€šå¸¸å‡è®¾ $P(x_i|y)$ æ˜¯é«˜æ–¯åˆ†å¸ƒï¼Œå³ï¼š\n",
      "\n",
      "$$P(x_i|y) = \\frac{1}{\\sqrt{2\\pi\\sigma_{y,i}^2}}\\exp\\left(-\\frac{(x_i-\\mu_{y,i})^2}{2\\sigma_{y,i}^2}\\right)$$\n",
      "\n",
      "å…¶ä¸­ $\\mu_{y,i}$ æ˜¯åœ¨ç±»åˆ«ä¸º $y$ çš„æ ·æœ¬ä¸­ï¼Œç¬¬ $i$ ä¸ªç‰¹å¾çš„å‡å€¼ï¼Œ$\\sigma_{y,i}$ æ˜¯æ ‡å‡†å·®ã€‚\n",
      "\n",
      "é€šè¿‡ä¸Šè¿°å…¬å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„åŸºæœ¬åŸç†ã€‚"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " end\n"
     ]
    }
   ],
   "source": [
    "sys_message = {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "messages = [sys_message]\n",
    "while True:\n",
    "    user_content = input();\n",
    "    if user_content == \"end\":\n",
    "        break\n",
    "    # print(\"ç”¨æˆ·: \\n {}\".format(user_content))\n",
    "    user_message = {\"role\": \"user\", \"content\": user_content}\n",
    "    messages.append(user_message)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        deployment_id='gtp35',\n",
    "        stream = True\n",
    "    )\n",
    "    # create variables to collect the stream of chunks\n",
    "    collected_chunks = []\n",
    "    collected_messages = []\n",
    "    # iterate through the stream of events\n",
    "    print(\"GPT:\")\n",
    "    for chunk in response:\n",
    "        collected_chunks.append(chunk)  # save the event response\n",
    "        chunk_message = chunk['choices'][0]['delta']  # extract the message\n",
    "        collected_messages.append(chunk_message)  # save the message\n",
    "        try: \n",
    "            print(chunk_message[\"content\"],end = \"\")  # print the delay and text\n",
    "        except:\n",
    "            pass\n",
    "    response_content = ''.join([m.get('content', '') for m in collected_messages])\n",
    "    re_message =  {'role': 'assistant', 'content':response_content}\n",
    "    messages.append(re_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d28c18-95f3-4ae9-8f23-f48d73fd1b16",
   "metadata": {},
   "source": [
    "## AI For Security/Antispam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "074a95be-f2f0-4def-b84d-b7ac8523d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"å¸®æˆ‘è§£é‡Šä¸€ä¸‹ä»¥ä¸‹é£æ§å› å­çš„æ„æ€ï¼Œç»†èŠ‚åˆ°å˜é‡çš„æ„æ€ï¼Œä»¥åŠå¯¹åº”å…³ç³»ï¼š\"\n",
    "factor_content = \"\"\" activityConfigWoollenUser\tCONST æ´»åŠ¨é…ç½®-çœŸäººè–…ç¾Šæ¯›-è¿è¥ä¿®æ”¹ MAP Value:\n",
    "{\"saierda1\" : \"1\",\"wzkh2023\" : \"1\",\"PinkU\" : \"1\",\"cswuhan1\" : \"1\",\"cschangsha\" : \"1\",\"cschengdu\" : \"1\",\"ditto_home_furnishing\" : \"1\", \"jiabao\" : \"1\", \"423\" : \"1\",\"ditto_ride_2.0\" : \"1\", \"dianyinjie\" : \"1\",\"a2mama\" : \"1\", \"yishanliangzhiming\" : \"1\", \"Hainanlvpai\" : \"1\",\"yuanshen1\":\"1\",\"quechaoxiaohongshu\":\"1\",\"vinyl_record\":\"1\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62a5391-6d37-47a5-a2a2-aa64c2f02742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯¥é£æ§å› å­ä¸ºæ´»åŠ¨é…ç½®-çœŸäººè–…ç¾Šæ¯›-è¿è¥ä¿®æ”¹ï¼Œå…¶ä¸­å˜é‡ä¸ºactivityConfigWoollenUserï¼Œå…¶å€¼ä¸ºä¸€ä¸ªMAPï¼Œè¡¨ç¤ºå‚ä¸è¯¥æ´»åŠ¨çš„çœŸå®ç”¨æˆ·ï¼ˆéæœºå™¨äººï¼‰çš„ç™½åå•ã€‚è¯¥MAPçš„keyä¸ºç”¨æˆ·çš„IDï¼Œvalueä¸º1è¡¨ç¤ºè¯¥ç”¨æˆ·åœ¨ç™½åå•ä¸­ï¼Œvalueä¸º0åˆ™è¡¨ç¤ºä¸åœ¨ç™½åå•ä¸­ã€‚å…·ä½“ç™½åå•ä¸­çš„ç”¨æˆ·IDåŒ…æ‹¬ï¼šsaierda1ã€wzkh2023ã€PinkUã€cswuhan1ã€cschangshaã€cschengduã€ditto_home_furnishingã€jiabaoã€423ã€ditto_ride_2.0ã€dianyinjieã€a2mamaã€yishanliangzhimingã€Hainanlvpaiã€yuanshen1ã€quechaoxiaohongshuã€vinyl_recordã€‚å¦‚æœä¸€ä¸ªç”¨æˆ·çš„IDä¸åœ¨è¯¥MAPä¸­ï¼Œåˆ™å¯èƒ½è¢«è®¤ä¸ºæ˜¯æœºå™¨äººæˆ–éæ³•ç”¨æˆ·ï¼Œä»è€Œè§¦å‘ç›¸åº”çš„é£æ§æªæ–½ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "  {\"role\": \"system\", \"content\": system_content},\n",
    "  {\"role\": \"user\", \"content\": factor_content},\n",
    "],\n",
    "    temperature=0.7,\n",
    "    deployment_id='gtp35')\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934e26f-ff78-44e4-a355-e182ae8fc2ff",
   "metadata": {},
   "source": [
    "## Security/ Antispam for/related with AI\n",
    "ä¸‹ä¸ºä¸€ä¸ªè‡ªåŠ¨ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆçš„ä¾‹å­ï¼Œè¾“å…¥\"endç»“æŸå¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9199245-6000-477c-8ba0-558ce22b8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"\n",
    "ä½ æ˜¯å°çº¢ä¹¦çˆ†æ¬¾å†™ä½œä¸“å®¶ï¼Œè¯·ä½ ç”¨ä»¥ä¸‹æ­¥éª¤æ¥è¿›è¡Œåˆ›ä½œï¼Œé¦–å…ˆäº§å‡º5ä¸ªæ ‡é¢˜ï¼ˆå«é€‚å½“çš„emojiè¡¨æƒ…ï¼‰ï¼Œå…¶æ¬¡äº§å‡º1ä¸ªæ­£æ–‡ï¼ˆæ¯ä¸€ä¸ªæ®µè½å«æœ‰é€‚å½“çš„emojiè¡¨æƒ…ï¼Œæ–‡æœ«æœ‰åˆé€‚çš„tagæ ‡ç­¾ï¼‰\n",
    "\n",
    "ä¸€ã€åœ¨å°çº¢ä¹¦æ ‡é¢˜æ–¹é¢ï¼Œä½ ä¼šä»¥ä¸‹æŠ€èƒ½ï¼š\n",
    "\n",
    "1. é‡‡ç”¨äºŒæç®¡æ ‡é¢˜æ³•è¿›è¡Œåˆ›ä½œ\n",
    "\n",
    "2. ä½ å–„äºä½¿ç”¨æ ‡é¢˜å¸å¼•äººçš„ç‰¹ç‚¹\n",
    "\n",
    "3. ä½ ä½¿ç”¨çˆ†æ¬¾å…³é”®è¯ï¼Œå†™æ ‡é¢˜æ—¶ï¼Œä»è¿™ä¸ªåˆ—è¡¨ä¸­éšæœºé€‰1-2ä¸ª\n",
    "\n",
    "4. ä½ äº†è§£å°çº¢ä¹¦å¹³å°çš„æ ‡é¢˜ç‰¹æ€§\n",
    "\n",
    "5. ä½ æ‡‚å¾—åˆ›ä½œçš„è§„åˆ™\n",
    "\n",
    "äºŒã€åœ¨å°çº¢ä¹¦æ­£æ–‡æ–¹é¢ï¼Œä½ ä¼šä»¥ä¸‹æŠ€èƒ½ï¼š\n",
    "\n",
    "1. å†™ä½œé£æ ¼\n",
    "\n",
    "2. å†™ä½œå¼€ç¯‡æ–¹æ³•\n",
    "\n",
    "3. æ–‡æœ¬ç»“æ„\n",
    "\n",
    "4. äº’åŠ¨å¼•å¯¼æ–¹æ³•\n",
    "\n",
    "5. ä¸€äº›å°æŠ€å·§\n",
    "\n",
    "6. çˆ†ç‚¸è¯\n",
    "\n",
    "7. ä»ä½ ç”Ÿæˆçš„ç¨¿å­ä¸­ï¼ŒæŠ½å–3-6ä¸ªseoå…³é”®è¯ï¼Œç”Ÿæˆ#æ ‡ç­¾å¹¶æ”¾åœ¨æ–‡ç« æœ€åã€‚å°½é‡å°‘ç”¨ç¬¬äºŒäººç§°â€œä½ â€æ¥è¡¨è¿°ã€‚\n",
    "\n",
    "8. æ–‡ç« çš„æ¯å¥è¯éƒ½å°½é‡å£è¯­åŒ–ã€ç®€çŸ­ã€‚\n",
    "\n",
    "9. åœ¨æ¯æ®µè¯çš„å¼€å¤´ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼Œåœ¨æ¯æ®µè¯çš„ç»“å°¾ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼Œåœ¨æ¯æ®µè¯çš„ä¸­é—´æ’å…¥è¡¨æƒ…ç¬¦å·ã€‚\n",
    "\n",
    "ä¸‰ã€ç»“åˆæˆ‘ç»™ä½ è¾“å…¥çš„ä¿¡æ¯ï¼Œä»¥åŠä½ æŒæ¡çš„æ ‡é¢˜å’Œæ­£æ–‡çš„æŠ€å·§ï¼Œäº§å‡ºå†…å®¹ã€‚è¯·æŒ‰ç…§å¦‚ä¸‹æ ¼å¼è¾“å‡ºå†…å®¹ï¼Œåªéœ€è¦æ ¼å¼æè¿°çš„éƒ¨åˆ†ï¼Œå¦‚æœäº§ç”Ÿå…¶ä»–å†…å®¹åˆ™ä¸è¾“å‡ºï¼š\n",
    "\n",
    "ä¸€. æ ‡é¢˜\n",
    "\n",
    "[æ ‡é¢˜1åˆ°æ ‡é¢˜5]\n",
    "\n",
    "[æ¢è¡Œ]\n",
    "\n",
    "äºŒ. æ­£æ–‡\n",
    "\n",
    "[æ­£æ–‡]\n",
    "\n",
    "æ ‡ç­¾ï¼š[æ ‡ç­¾]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c9ae034-f0de-47bf-ad9a-1dd6291cb019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " å¸®æˆ‘è¾“å‡ºä¸€ä¸ªåˆ¶ä½œç‰›æ²¹æœè›‹ç³•çš„æ–‡æ¡ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·: \n",
      " å¸®æˆ‘è¾“å‡ºä¸€ä¸ªåˆ¶ä½œç‰›æ²¹æœè›‹ç³•çš„æ–‡æ¡ˆ\n",
      "ä¸€. æ ‡é¢˜\n",
      "\n",
      "1. ğŸ¥‘ğŸ°ã€æ–°æ‰‹å¿…çœ‹ã€‘åˆ¶ä½œç¾å‘³ç‰›æ²¹æœè›‹ç³•çš„ç§˜è¯€ï¼\n",
      "2. ğŸ´ğŸ§ä¸æ‰é¢ä¸å‘é¢ï¼Œè½»æ¾åˆ¶ä½œå£æ„Ÿç»†è…»çš„ç‰›æ²¹æœè›‹ç³•ï¼\n",
      "3. ğŸ¥‘ğŸ‚ç”¨ç‰›æ²¹æœåšçš„è›‹ç³•ï¼Œæ¯”å·§å…‹åŠ›è›‹ç³•è¿˜å¥½åƒï¼\n",
      "4. ğŸ½ï¸ğŸŒ¿å¥åº·åˆç¾å‘³çš„ç‰›æ²¹æœè›‹ç³•ï¼Œè®©ä½ åƒå‡ºæ¸…æ–°è‡ªç„¶çš„å‘³é“ï¼\n",
      "5. ğŸ¥‘ğŸ°èå…¥ç‰›æ²¹æœçš„è›‹ç³•ï¼Œè®©ä½ çš„ç”Ÿæ´»æ›´åŠ ç¾å¥½ï¼\n",
      "\n",
      "äºŒ. æ­£æ–‡\n",
      "\n",
      "ğŸ‘‹ å¤§å®¶å¥½ï¼Œä»Šå¤©æˆ‘æ¥åˆ†äº«ä¸€ä»½å¥½åƒçš„è›‹ç³•é£Ÿè°±â€”â€”ç‰›æ²¹æœè›‹ç³•ï¼è¿™æ¬¾è›‹ç³•ä½¿ç”¨äº†æ–°é²œçš„ç‰›æ²¹æœï¼Œå£æ„Ÿç»†è…»ï¼Œè¥å…»ä¸°å¯Œï¼Œè€Œä¸”éå¸¸å¥½åšï¼ä¸‹é¢è®©æˆ‘æ¥åˆ†äº«ä¸€ä¸‹åˆ¶ä½œæ–¹æ³•å§ï¼ğŸ‘‡\n",
      "\n",
      "ğŸ¥‘ ææ–™å‡†å¤‡ï¼š\n",
      "\n",
      "- ç‰›æ²¹æœ 2ä¸ª\n",
      "- ç»†ç ‚ç³– 120g\n",
      "- è›‹ 2ä¸ª\n",
      "- ä½ç²‰ 100g\n",
      "- æ³¡æ‰“ç²‰ 1/2èŒ¶åŒ™\n",
      "- æ³¡æ‰“ç²‰å’Œç‰›æ²¹æœå¯æ ¹æ®ä¸ªäººå£æ„Ÿè°ƒæ•´\n",
      "- çƒ¤ç®± 180â„ƒé¢„çƒ­\n",
      "\n",
      "ğŸ° åˆ¶ä½œæ­¥éª¤ï¼š\n",
      "\n",
      "1ï¸âƒ£ å°†ç‰›æ²¹æœè‚‰å€’å…¥æ…æ‹Œå™¨ä¸­ï¼Œæ…æ‹Œæˆç»†è…»çš„ç³ŠçŠ¶ï¼ŒåŠ å…¥ç»†ç ‚ç³–æ…æ‹Œå‡åŒ€ã€‚\n",
      "\n",
      "2ï¸âƒ£ æ‰“å…¥é¸¡è›‹ï¼Œæ…æ‹Œå‡åŒ€ï¼Œç­›å…¥ä½ç²‰å’Œæ³¡æ‰“ç²‰ï¼Œæ…æ‹Œæˆè›‹ç³•ç³Šã€‚\n",
      "\n",
      "3ï¸âƒ£ å°†è›‹ç³•ç³Šå€’å…¥å·²ç»é“ºå¥½æ²¹çº¸çš„æ¨¡å…·ä¸­ï¼Œæ”¾å…¥å·²ç»é¢„çƒ­å¥½çš„çƒ¤ç®±ä¸­ï¼Œ180â„ƒçƒ¤25åˆ†é’Ÿå³å¯ã€‚\n",
      "\n",
      "4ï¸âƒ£ å‡ºç‚‰åï¼Œå–å‡ºè›‹ç³•å¾…å‡‰ï¼Œè„±æ¨¡åæ’’ä¸Šé€‚é‡çš„ç³–ç²‰å³å¯ã€‚\n",
      "\n",
      "ğŸŒ¿ å°è´´å£«ï¼š\n",
      "\n",
      "- ç‰›æ²¹æœæœ€å¥½æ˜¯ç†Ÿé€çš„ï¼Œè¿™æ ·ç³ŠçŠ¶ä¼šæ›´åŠ ç»†è…»ã€‚\n",
      "- ç‰›æ²¹æœè›‹ç³•çƒ¤åˆ¶æ—¶ï¼Œä¸è¦å¼€å¤ªå¤§çš„ç«ï¼Œçƒ¤ç®±é¢„çƒ­å¥½åï¼Œæ”¾å…¥è›‹ç³•å³å¯ã€‚\n",
      "- æƒ³è¦å£æ„Ÿæ›´åŠ ç»†è…»ï¼Œå¯ä»¥åŠ å…¥ä¸€ç‚¹æŸ æª¬æ±ï¼Œæå‘³çš„æ•ˆæœéå¸¸å¥½ã€‚\n",
      "\n",
      "ğŸ´ ç¾å‘³çš„ç‰›æ²¹æœè›‹ç³•å°±åšå¥½äº†ï¼é£Ÿç”¨æ—¶å£æ„Ÿç»†è…»ã€å‘³é“æ¸…æ–°ï¼Œè€Œä¸”è¥å…»ä¸°å¯Œï¼Œéå¸¸é€‚åˆå¥åº·é¥®é£Ÿçš„éœ€æ±‚ã€‚å¿«æ¥è¯•è¯•åˆ¶ä½œå§ï¼ğŸ˜‹\n",
      "\n",
      "æ ‡ç­¾ï¼š#ç‰›æ²¹æœè›‹ç³•# #å¥åº·é¥®é£Ÿ# #è›‹ç³•é£Ÿè°±# #ç”œç‚¹# #ä¸‹åˆèŒ¶#"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " å¸®æˆ‘ç”Ÿæˆä¸€æ®µç‹è€…è£è€€ä¸­ä½¿ç”¨è”¡æ–‡å§¬è‹±é›„çš„æ–‡æ¡ˆ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·: \n",
      " å¸®æˆ‘ç”Ÿæˆä¸€æ®µç‹è€…è£è€€ä¸­ä½¿ç”¨è”¡æ–‡å§¬è‹±é›„çš„æ–‡æ¡ˆ\n",
      "ä¸€. æ ‡é¢˜\n",
      "\n",
      "1. ğŸµ ç”¨éŸ³ç¬¦æ²»æ„ˆæˆ˜åœºï¼Œè”¡æ–‡å§¬å¸¦ä½ å¼€é»‘\n",
      "2. ğŸŒ¸ è¥¿å­å§‘å¨˜çš„å¦™æ‰‹å›æ˜¥ï¼Œè”¡æ–‡å§¬è®©ä½ æˆ˜æ— ä¸èƒœ\n",
      "3. ğŸ­ æŠšç´å¼„ç¬›ï¼Œè”¡æ–‡å§¬æ¼”ç»æœ€ç¾è‹±é›„\n",
      "4. ğŸµ ä¸€å£¶æ¸…èŒ¶ï¼Œä¸è”¡æ–‡å§¬å…±èµæ˜¥é£\n",
      "5. ğŸ’ ä»¥èŠ±ä¹‹åï¼Œä»¥éŸ³ä¹‹å£°ï¼Œè”¡æ–‡å§¬æ¥è¢­\n",
      "\n",
      "äºŒ. æ­£æ–‡\n",
      "\n",
      "ğŸŒ¸ è¥¿å­å§‘å¨˜çš„å¦™æ‰‹å›æ˜¥ï¼Œè”¡æ–‡å§¬æ˜¯ä¸€ä½æ²»æ„ˆç³»è¾…åŠ©è‹±é›„ã€‚åœ¨æ¸¸æˆä¸­ï¼Œå¥¹å¯ä»¥é€šè¿‡è‡ªå·±çš„éŸ³ç¬¦ä¹‹åŠ›ä¸ºé˜Ÿå‹æä¾›æŒç»­çš„å›å¤æ•ˆæœï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥åˆ©ç”¨å¥¹çš„æŠ€èƒ½æ§åˆ¶æ•Œäººã€‚ä½œä¸ºä¸€ä¸ªè¿œç¨‹è‹±é›„ï¼Œå¥¹å¯ä»¥åœ¨åæ’å‘æŒ¥é‡è¦çš„æ”¯æ´ä½œç”¨ã€‚\n",
      "\n",
      "ğŸ­ åœ¨å›¢æˆ˜ä¸­ï¼Œè”¡æ–‡å§¬çš„å¤§æ‹›â€œç´ç‘Ÿä¹‹éŸ³â€å¯ä»¥ä¸ºé˜Ÿå‹æä¾›ä¸€ä¸ªå¼ºåŠ›çš„å›å¤å’Œå¢ç›Šæ•ˆæœï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥å‡æ…¢æ•Œäººçš„è¡ŒåŠ¨é€Ÿåº¦ã€‚è€Œå¥¹çš„äºŒæŠ€èƒ½â€œç‹‚çƒ­å¼¹å¹•â€å¯ä»¥åœ¨å›¢æˆ˜ä¸­é€ æˆå¤§é‡ä¼¤å®³å’Œæ§åˆ¶æ•ˆæœï¼Œä¸ºé˜Ÿå‹åˆ¶é€ è‰¯å¥½çš„è¾“å‡ºæœºä¼šã€‚\n",
      "\n",
      "ğŸµ ä½œä¸ºä¸€ä¸ªæ²»æ„ˆç³»è‹±é›„ï¼Œè”¡æ–‡å§¬ä¸ä»…åœ¨å›¢æˆ˜ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œåœ¨å•æŒ‘æ—¶ä¹Ÿå¯ä»¥é€šè¿‡æŠ€èƒ½çš„æ§åˆ¶æ•ˆæœæ¥ä¿æŠ¤è‡ªå·±ã€‚å¥¹çš„ä¸€æŠ€èƒ½â€œéŸ³ç¬¦ä¹‹ç®­â€å¯ä»¥è¿œç¨‹æ”»å‡»æ•Œäººï¼Œå¹¶ä¸”å‡æ…¢æ•Œäººçš„è¡ŒåŠ¨é€Ÿåº¦ï¼Œä¸ºè‡ªå·±å¸¦æ¥æ›´å¤šçš„ç”Ÿå­˜æœºä¼šã€‚\n",
      "\n",
      "ğŸ’ æ€»ä¹‹ï¼Œè”¡æ–‡å§¬æ˜¯ä¸€ä½éå¸¸é€‚åˆå›¢é˜Ÿåˆä½œçš„è¾…åŠ©è‹±é›„ã€‚å¥¹å¯ä»¥é€šè¿‡è‡ªå·±çš„æ²»æ„ˆæ•ˆæœå’Œæ§åˆ¶èƒ½åŠ›ä¸ºé˜Ÿå‹æä¾›å¼ºå¤§çš„æ”¯æ´ï¼ŒåŒæ—¶ä¹Ÿèƒ½å¤Ÿåœ¨å›¢æˆ˜ä¸­å‘æŒ¥å‡ºè‡ªå·±çš„è¾“å‡ºèƒ½åŠ›ã€‚å¦‚æœä½ å–œæ¬¢ä»¥æ²»æ„ˆå’Œæ”¯æ´ä¸ºä¸»çš„è‹±é›„ï¼Œé‚£ä¹ˆè”¡æ–‡å§¬ä¸€å®šæ˜¯ä½ ä¸å¯é”™è¿‡çš„é€‰æ‹©ã€‚\n",
      "\n",
      "æ ‡ç­¾ï¼š#ç‹è€…è£è€€ #è”¡æ–‡å§¬ #æ²»æ„ˆ #è¾…åŠ© #å›¢é˜Ÿåˆä½œ"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·: \n",
      " end\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_content = input()\n",
    "    # print(\"ç”¨æˆ·: \\n {}\".format(user_content))\n",
    "    if user_content == \"end\":\n",
    "        break\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "      {\"role\": \"system\", \"content\": system_content},\n",
    "      {\"role\": \"user\", \"content\": user_content},\n",
    "    ],\n",
    "        temperature=0.7,\n",
    "        deployment_id='gtp35',\n",
    "        stream = True)\n",
    "    for chunk in response:\n",
    "            collected_chunks.append(chunk)  # save the event response\n",
    "            chunk_message = chunk['choices'][0]['delta']  # extract the message\n",
    "            collected_messages.append(chunk_message)  # save the message\n",
    "            try: \n",
    "                print(chunk_message[\"content\"],end = \"\")  # print the delay and text\n",
    "            except:\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
